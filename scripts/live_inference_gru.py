# live_inference_gru.py â€” ë¶™ì—¬ë„£ê³  ë°”ë¡œ ì‹¤í–‰
import os, time, json, subprocess, warnings
import numpy as np
import cv2
import mediapipe as mp
from collections import deque, Counter
from tensorflow.keras.models import load_model
import joblib

# ===================== ê²½ë¡œ/ê³ ì • ì„¤ì • =====================
DATA_DIR = "../data"
MODEL_DIR = "../model"
CONFIG_PATH = os.path.join(DATA_DIR, "dataset_config.json")
LABEL_PATH = os.path.join(MODEL_DIR, "label_encoder.pkl")

# ëª¨ë¸ í›„ë³´(ì¡´ì¬í•˜ëŠ” ì²« íŒŒì¼ì„ ì‚¬ìš©)
CANDIDATE_MODELS = [
    os.path.join(MODEL_DIR, "gesture_gru_best.keras"),
    os.path.join(MODEL_DIR, "gesture_gru_final.keras"),
    os.path.join(MODEL_DIR, "gesture_gru_model.h5"),  # êµ¬ë²„ì „ í˜¸í™˜
]

# ì¶”ë¡  ì•ˆì •í™”/ì¶œë ¥ íŒŒë¼ë¯¸í„°
P_THRESH = 0.50         # softmax í™•ë¥  ì„ê³„ì¹˜
STABLE_WINDOW = 4       # ìµœê·¼ Nê°œ ì˜ˆì¸¡ ë³´ê´€
STABLE_MIN = 4          # ê·¸ì¤‘ ë™ì¼ ë¼ë²¨ ìµœì†Œ ê°œìˆ˜
COOLDOWN_SEC = 0.8      # ì¬ë°œë™ ì¿¨ë‹¤ìš´(ì´ˆ)
PRINT_INTERVAL = 0.5    # ì½˜ì†” ë¼ë²¨ ì¶œë ¥ ì£¼ê¸°(ì´ˆ)

# ===================== dataset_config ë¡œë“œ =====================
if os.path.exists(CONFIG_PATH):
    with open(CONFIG_PATH, "r") as f:
        cfg = json.load(f)
    SEQUENCE_LENGTH = int(cfg.get("sequence_length", 10))
    FEATURE_DIM = int(cfg.get("feature_dim", 66))
    USE_STANDARDIZE = bool(cfg.get("use_standardize", True))
    VIS_THRESH = float(cfg.get("vis_thresh", 0.5))
    USE_Z = (FEATURE_DIM == 99)
else:
    warnings.warn("[ê²½ê³ ] dataset_config.jsonì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì§‘/í•™ìŠµê³¼ ì…ë ¥ ì°¨ì›ì´ ë‹¤ë¥´ë©´ ì˜¤ë¥˜ê°€ ë‚©ë‹ˆë‹¤.")
    SEQUENCE_LENGTH = 10
    FEATURE_DIM = 66
    USE_STANDARDIZE = True
    VIS_THRESH = 0.5
    USE_Z = False

print(f"[INFO] Expected per-seq shape: (T={SEQUENCE_LENGTH}, F={FEATURE_DIM}), "
      f"mode={'xyz' if USE_Z else 'xy'}, standardize={USE_STANDARDIZE}")

# ===================== ëª¨ë¸/ë¼ë²¨ ë¡œë“œ & ê²€ì¦ =====================
model_path = next((p for p in CANDIDATE_MODELS if os.path.exists(p)), None)
if model_path is None:
    raise FileNotFoundError(
        "ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ê²½ë¡œ ì¤‘ í•˜ë‚˜ì— ëª¨ë¸ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n" +
        "\n".join(" - " + p for p in CANDIDATE_MODELS)
    )

model = load_model(model_path)
le = joblib.load(LABEL_PATH)

num_units = model.output_shape[-1]
num_labels = len(le.classes_)
print(f"[INFO] Loaded model: {model_path}")
print(f"[INFO] model units={num_units}, label classes={num_labels} -> {le.classes_.tolist()}")

if num_units != num_labels:
    raise RuntimeError(
        f"ëª¨ë¸ê³¼ ë¼ë²¨ ì¸ì½”ë” ë¶ˆì¼ì¹˜: model units={num_units}, labels={num_labels}\n"
        f"â†’ ê°™ì€ í•™ìŠµ ì„¸ì…˜ì—ì„œ ì €ì¥ëœ model(.keras/.h5)ê³¼ label_encoder.pkl í˜ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    )

# ===================== MediaPipe Pose ì¤€ë¹„ =====================
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(model_complexity=1, enable_segmentation=False)
mp_drawing = mp.solutions.drawing_utils

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    raise SystemExit

print("ğŸ¥ ì‹¤ì‹œê°„ GRU ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘ (ESCë¡œ ì¢…ë£Œ)")
seq_buf = deque(maxlen=SEQUENCE_LENGTH)  # ì „ì²˜ë¦¬ëœ ë²¡í„° ë²„í¼
pred_buf = deque(maxlen=STABLE_WINDOW)
last_fire = 0.0

# ì½˜ì†” ì¶œë ¥ ìƒíƒœ
last_print_time = 0.0
display_lbl = "-"      # í™”ë©´/ì½˜ì†” í‘œì‹œìš© í˜„ì¬ ë¼ë²¨
display_p = 0.0

# ===================== ì „ì²˜ë¦¬ ìœ í‹¸ (ìˆ˜ì§‘/í•™ìŠµ ë™ì¼) =====================
# Mediapipe landmark ì¸ë±ìŠ¤
NOSE = 0
L_SHOULDER, R_SHOULDER = 11, 12
L_ELBOW, R_ELBOW = 13, 14
L_HIP, R_HIP = 23, 24

EPS = 1e-6

def _is_visible(lmk, idx, thresh=VIS_THRESH):
    try:
        return lmk[idx].visibility >= thresh
    except Exception:
        return False

def _pick_origin_and_scale(coords, lmk):
    """
    coords: (33, D) (D=2 or 3)
    origin/scale ìš°ì„ ìˆœìœ„:
      - origin: (ê³¨ë°˜ì¤‘ì‹¬) > (ì–´ê¹¨ì¤‘ì‹¬) > (ì–´ê¹¨/ì½” ì¤‘ì ) > (ìƒì²´ í‰ê· ) > (0)
      - scale:  (ì–´ê¹¨ë„ˆë¹„) > (ì–´ê¹¨-ì½”) > (ìƒì²´ ë°•ìŠ¤ ëŒ€ê°ì„ ) > 1
    """
    def center(a, b): return (a + b) / 2.0
    def dist(a, b): return float(np.linalg.norm(a - b))

    have_lhip = _is_visible(lmk, L_HIP)
    have_rhip = _is_visible(lmk, R_HIP)
    have_lsho = _is_visible(lmk, L_SHOULDER)
    have_rsho = _is_visible(lmk, R_SHOULDER)
    have_nose = _is_visible(lmk, NOSE)

    # 1) ê³¨ë°˜ ë‘˜ ë‹¤ ë³´ì„
    if have_lhip and have_rhip:
        origin = center(coords[L_HIP], coords[R_HIP])
        if have_lsho and have_rsho:
            scale = dist(coords[L_SHOULDER], coords[R_SHOULDER])
            if scale > EPS: return origin, scale
        upper = [i for i in [NOSE, L_SHOULDER, R_SHOULDER, L_ELBOW, R_ELBOW] if _is_visible(lmk, i)]
        if upper:
            box = coords[upper]
            diag = float(np.linalg.norm(box.max(axis=0) - box.min(axis=0)))
            return origin, (diag if diag > EPS else 1.0)
        return origin, 1.0

    # 2) ì–´ê¹¨ ë‘˜ ë‹¤ ë³´ì„
    if have_lsho and have_rsho:
        origin = center(coords[L_SHOULDER], coords[R_SHOULDER])
        scale = dist(coords[L_SHOULDER], coords[R_SHOULDER])
        if scale > EPS: return origin, scale
        if have_nose:
            alt = dist(coords[L_SHOULDER], coords[NOSE])
            if alt > EPS: return origin, alt
        upper = [i for i in [NOSE, L_SHOULDER, R_SHOULDER, L_ELBOW, R_ELBOW] if _is_visible(lmk, i)]
        if upper:
            box = coords[upper]
            diag = float(np.linalg.norm(box.max(axis=0) - box.min(axis=0)))
            return origin, (diag if diag > EPS else 1.0)
        return origin, 1.0

    # 3) í•œìª½ ì–´ê¹¨ + ì½”
    if have_nose and (have_lsho or have_rsho):
        s_idx = L_SHOULDER if have_lsho else R_SHOULDER
        origin = (coords[s_idx] + coords[NOSE]) / 2.0
        scale = float(np.linalg.norm(coords[s_idx] - coords[NOSE]))
        return origin, (scale if scale > EPS else 1.0)

    # 4) ìƒì²´ í‰ê· /ë°•ìŠ¤ ëŒ€ê°ì„ 
    upper = [i for i in [NOSE, L_SHOULDER, R_SHOULDER, L_ELBOW, R_ELBOW] if _is_visible(lmk, i)]
    if upper:
        box = coords[upper]
        origin = box.mean(axis=0)
        diag = float(np.linalg.norm(box.max(axis=0) - box.min(axis=0)))
        return origin, (diag if diag > EPS else 1.0)

    # 5) ì •ë§ ì—†ìœ¼ë©´ (0), 1
    return np.zeros((coords.shape[1],), dtype=np.float32), 1.0

def preprocess_landmarks(pose_landmarks):
    """
    ì…ë ¥: mediapipe pose_landmarks.landmark (ê¸¸ì´ 33)
    ì¶œë ¥: (FEATURE_DIM,) ì „ì²˜ë¦¬ ë²¡í„°
      - ê¸°ì¤€ì  ì´ë™(ê³¨ë°˜/ì–´ê¹¨/ì½”/ìƒì²´)
      - ìŠ¤ì¼€ì¼ ì •ê·œí™”(ì–´ê¹¨ë„ˆë¹„/ì–´ê¹¨-ì½”/ìƒì²´ë°•ìŠ¤)
      - (ì˜µì…˜) ì¶•ë³„ í‘œì¤€í™”
    """
    lm = pose_landmarks.landmark
    if USE_Z:
        coords = np.array([[l.x, l.y, l.z] for l in lm], dtype=np.float32)  # (33,3) -> 99
    else:
        coords = np.array([[l.x, l.y] for l in lm], dtype=np.float32)       # (33,2) -> 66

    origin, scale = _pick_origin_and_scale(coords, lm)
    coords = (coords - origin) / (scale if scale > EPS else 1.0)

    if USE_STANDARDIZE:
        mean = coords.mean(axis=0, keepdims=True)
        std = coords.std(axis=0, keepdims=True) + 1e-6
        coords = (coords - mean) / std

    flat = coords.flatten()
    if flat.shape[0] != FEATURE_DIM:
        raise ValueError(f"ì „ì²˜ë¦¬ ê²°ê³¼ ì°¨ì› ë¶ˆì¼ì¹˜: {flat.shape[0]} != {FEATURE_DIM}")
    return flat

# ===================== ì•¡ì…˜ íŠ¸ë¦¬ê±° =====================
def trigger_action(label: str):
    """ë¼ë²¨ì— ë”°ë¼ í™”ë©´ ìŠ¤ì™€ì´í”„ ë‹¨ì¶•í‚¤ ì „ì†¡"""
    try:
        if label == "sliding_left":
            subprocess.run(["xdotool", "key", "Alt+Left"], check=False)
        elif label == "sliding_right":
            subprocess.run(["xdotool", "key", "Alt+Right"], check=False)
        else:
            return
        print(f"âš¡ action fired: {label}")
    except FileNotFoundError:
        print("âš  xdotoolì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. sudo apt install xdotool ë˜ëŠ” Wayland ëŒ€ì•ˆì„ ì‚¬ìš©í•˜ì„¸ìš”.")

# ====== ë©”ì¸ ë£¨í”„ (ì´ ë¸”ë¡ìœ¼ë¡œ êµì²´) ======
raw_lbl, raw_p = "-", 0.0
gated_lbl, gated_p = "-", 0.0
stable_lbl, stable_cnt = "-", 0
last_fire = 0.0
last_print_time = 0.0

while True:
    ret, frame = cap.read()
    if not ret:
        break

    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(rgb)

    if result.pose_landmarks:
        # ë¼ˆëŒ€ ê·¸ë¦¬ê¸°
        mp_drawing.draw_landmarks(
            frame,
            result.pose_landmarks,
            mp_pose.POSE_CONNECTIONS,
            mp_drawing.DrawingSpec(thickness=2, circle_radius=2),
            mp_drawing.DrawingSpec(thickness=2),
        )

        # ì „ì²˜ë¦¬ + ë²„í¼ ì ì¬
        vec = preprocess_landmarks(result.pose_landmarks)  # (FEATURE_DIM,)
        seq_buf.append(vec)

        # ì¶©ë¶„íˆ ëª¨ì˜€ì„ ë•Œ ì¶”ë¡ 
        if len(seq_buf) == SEQUENCE_LENGTH:
            x = np.array([list(seq_buf)], dtype=np.float32)  # (1, T, F)
            prob = model.predict(x, verbose=0)[0]            # (num_classes,)
            p_max = float(np.max(prob))
            idx = int(np.argmax(prob))
            raw_lbl = le.classes_[idx] if 0 <= idx < len(le.classes_) else "-"
            raw_p = p_max

            # ì„ê³„ì¹˜ í†µê³¼(ê²Œì´íŠ¸) ë¼ë²¨
            if p_max >= P_THRESH:
                gated_lbl, gated_p = raw_lbl, p_max
                pred_buf.append(gated_lbl)   # ì•ˆì •í™” ë²„í¼ì—ëŠ” 'ê²Œì´íŠ¸ í†µê³¼'ë§Œ ë„£ìŒ
            else:
                gated_lbl, gated_p = "-", 0.0
                pred_buf.append("_")

            # ì•ˆì •í™” ë¼ë²¨ ê³„ì‚°
            counts = Counter([p for p in pred_buf if p != "_"])
            if counts:
                stable_lbl, stable_cnt = counts.most_common(1)[0]
            else:
                stable_lbl, stable_cnt = "-", 0

            # ì•¡ì…˜ íŠ¸ë¦¬ê±° (ì›í•˜ë©´ ì•ˆì •í™” ë¼ë²¨ì—ë§Œ ë°˜ì‘)
            now = time.time()
            if stable_lbl in ("sliding_left", "sliding_right") and stable_cnt >= STABLE_MIN:
                if now - last_fire >= COOLDOWN_SEC:
                    trigger_action(stable_lbl)
                    last_fire = now
                    pred_buf.clear()  # ì—°ì† íŠ¸ë¦¬ê±° ë°©ì§€
    else:
        raw_lbl, raw_p = "no_pose", 0.0
        gated_lbl, gated_p = "-", 0.0
        # pred_bufì—ëŠ” ì•„ë¬´ ê²ƒë„ ë„£ì§€ ì•ŠìŒ (ì¼ê´€ì„±)

    # ===== í™”ë©´ ì˜¤ë²„ë ˆì´: Raw / Gated / Stable ëª¨ë‘ í‘œì‹œ =====
    y0 = 28
    cv2.putText(frame, f"Raw:    {raw_lbl} ({raw_p:.2f})",
                (10, y0), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
    cv2.putText(frame, f"Gated:  {gated_lbl} ({gated_p:.2f})  [pth={P_THRESH:.2f}]",
                (10, y0+30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (180, 255, 120), 2)
    cv2.putText(frame, f"Stable: {stable_lbl} (cnt={stable_cnt}/{STABLE_WINDOW})",
                (10, y0+60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (120, 220, 255), 2)
    cv2.putText(frame, f"T={SEQUENCE_LENGTH} F={FEATURE_DIM}",
                (10, y0+90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (220, 220, 220), 2)

    cv2.imshow("Live Inference (GRU + MediaPipe overlay)", frame)

    # ===== ì½˜ì†”ì—ë„ 0.5ì´ˆë§ˆë‹¤ ë™ì¼ ì •ë³´ ì¶œë ¥ =====
    now = time.time()
    if now - last_print_time >= 0.5:
        print(f"[{time.strftime('%H:%M:%S')}] raw={raw_lbl}({raw_p:.2f}) | "
              f"gated={gated_lbl}({gated_p:.2f}) | stable={stable_lbl} cnt={stable_cnt}/{STABLE_WINDOW}")
        last_print_time = now

    if cv2.waitKey(1) & 0xFF == 27:  # ESC
        break


cap.release()
cv2.destroyAllWindows()
